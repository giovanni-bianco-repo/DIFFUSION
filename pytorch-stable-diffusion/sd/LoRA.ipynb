{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "x_dhQfFYXoPu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kaimao/Desktop/DIFFUSION/pytorch-stable-diffusion/venv/lib/python3.10/site-packages/lightning_fabric/__init__.py:41: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n"
          ]
        }
      ],
      "source": [
        "import model_loader\n",
        "import pipeline\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from transformers import CLIPTokenizer\n",
        "import torch\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "\n",
        "ALLOW_CUDA = True\n",
        "ALLOW_MPS = True\n",
        "\n",
        "if torch.cuda.is_available() and ALLOW_CUDA:\n",
        "    DEVICE = \"cuda\"\n",
        "elif (torch.has_mps or torch.backends.mps.is_available()) and ALLOW_MPS:\n",
        "    DEVICE = \"mps\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "tokenizer = CLIPTokenizer(\"../data/vocab.json\", merges_file=\"../data/merges.txt\")\n",
        "model_file = \"../data/v1-5-pruned-emaonly.ckpt\"\n",
        "models = model_loader.preload_models_from_standard_weights(model_file, DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'clip': CLIP(\n",
            "  (embedding): CLIPEmbedding(\n",
            "    (token_embedding): Embedding(49408, 768)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0-11): 12 x CLIPLayer(\n",
            "      (layernorm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (attention): SelfAttention(\n",
            "        (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (layernorm_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "      (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "), 'encoder': VAE_Encoder(\n",
            "  (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (2): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (4): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (5): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (7): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (8): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
            "  (10): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (11): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (12): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (13): VAE_AttentionBlock(\n",
            "    (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (attention): SelfAttention(\n",
            "      (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n",
            "      (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (14): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (15): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "  (16): SiLU()\n",
            "  (17): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "), 'decoder': VAE_Decoder(\n",
            "  (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (2): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (3): VAE_AttentionBlock(\n",
            "    (groupnorm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (attention): SelfAttention(\n",
            "      (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n",
            "      (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (4): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (5): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (6): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (7): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (8): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (10): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (11): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (12): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (16): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (17): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (18): Upsample(scale_factor=2.0, mode='nearest')\n",
            "  (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (21): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (22): VAE_ResidualBlock(\n",
            "    (groupnorm_1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (groupnorm_2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "    (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (residual_layer): Identity()\n",
            "  )\n",
            "  (23): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "  (24): SiLU()\n",
            "  (25): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "), 'diffusion': Diffusion(\n",
            "  (time_embedding): TimeEmbedding(\n",
            "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
            "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "  )\n",
            "  (unet): UNET(\n",
            "    (encoders): ModuleList(\n",
            "      (0): SwitchSequential(\n",
            "        (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (1-2): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): SwitchSequential(\n",
            "        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (4): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): SwitchSequential(\n",
            "        (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (7): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (9): SwitchSequential(\n",
            "        (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (10-11): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): SwitchSequential(\n",
            "      (0): UNET_ResidualBlock(\n",
            "        (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (residual_layer): Identity()\n",
            "      )\n",
            "      (1): UNET_AttentionBlock(\n",
            "        (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "        (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention_1): SelfAttention(\n",
            "          (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        )\n",
            "        (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention_2): CrossAttention(\n",
            "          (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "          (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "          (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        )\n",
            "        (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "        (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (2): UNET_ResidualBlock(\n",
            "        (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (residual_layer): Identity()\n",
            "      )\n",
            "    )\n",
            "    (decoders): ModuleList(\n",
            "      (0-1): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (2): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Upsample(\n",
            "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3-4): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Upsample(\n",
            "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Upsample(\n",
            "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (9): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (10-11): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (final): UNET_OutputLayer(\n",
            "    (groupnorm): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "    (conv): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")}\n",
            "model_name: clip params: 123060480\n",
            "model_name: encoder params: 34163664\n",
            "model_name: decoder params: 49490199\n",
            "model_name: diffusion params: 859520964\n",
            "Total parameters: 1066235307\n"
          ]
        }
      ],
      "source": [
        "print(models)\n",
        "\n",
        "total_params = 0\n",
        "for model_name, model in models.items():\n",
        "    print(f\"model_name: {model_name} params: {sum(p.numel() for p in model.parameters())}\")\n",
        "    total_params += sum(p.numel() for p in model.parameters())\n",
        "print(\"Total parameters:\", total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diffusion(\n",
            "  (time_embedding): TimeEmbedding(\n",
            "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
            "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "  )\n",
            "  (unet): UNET(\n",
            "    (encoders): ModuleList(\n",
            "      (0): SwitchSequential(\n",
            "        (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (1-2): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3): SwitchSequential(\n",
            "        (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (4): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): SwitchSequential(\n",
            "        (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (7): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (9): SwitchSequential(\n",
            "        (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "      )\n",
            "      (10-11): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): SwitchSequential(\n",
            "      (0): UNET_ResidualBlock(\n",
            "        (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (residual_layer): Identity()\n",
            "      )\n",
            "      (1): UNET_AttentionBlock(\n",
            "        (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "        (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention_1): SelfAttention(\n",
            "          (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        )\n",
            "        (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (attention_2): CrossAttention(\n",
            "          (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "          (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "          (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        )\n",
            "        (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "        (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "        (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (2): UNET_ResidualBlock(\n",
            "        (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (residual_layer): Identity()\n",
            "      )\n",
            "    )\n",
            "    (decoders): ModuleList(\n",
            "      (0-1): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (2): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): Upsample(\n",
            "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (3-4): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (5): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
            "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
            "          (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Upsample(\n",
            "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (6): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (7): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (8): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
            "            (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
            "          (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (2): Upsample(\n",
            "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (9): SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "      (10-11): 2 x SwitchSequential(\n",
            "        (0): UNET_ResidualBlock(\n",
            "          (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
            "          (conv_feature): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "          (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (residual_layer): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): UNET_AttentionBlock(\n",
            "          (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
            "          (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_1): SelfAttention(\n",
            "            (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (attention_2): CrossAttention(\n",
            "            (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
            "            (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
            "            (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
            "          )\n",
            "          (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
            "          (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
            "          (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
            "          (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (final): UNET_OutputLayer(\n",
            "    (groupnorm): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
            "    (conv): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "params: 859520964\n",
            "params num 862176708\n",
            "diffusion model trainable num 2655744\n"
          ]
        }
      ],
      "source": [
        "diffusion_model = models['diffusion']\n",
        "\n",
        "print(diffusion_model)\n",
        "print(f\"params: {sum(p.numel() for p in diffusion_model.parameters())}\")\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\n",
        "        \"attention_1.in_proj\",\n",
        "        \"attention_1.out_proj\",\n",
        "        \"attention_2.q_proj\",\n",
        "        \"attention_2.k_proj\",\n",
        "        \"attention_2.v_proj\",\n",
        "        \"attention_2.out_proj\",\n",
        "        \"conv_feature\",\n",
        "        \"conv_merged\",\n",
        "    ],\n",
        "    lora_dropout=0.0,\n",
        ")\n",
        "\n",
        "diffusion_model_lora = get_peft_model(diffusion_model, config)\n",
        "print(f\"params num {sum(p.numel() for p in diffusion_model_lora.parameters())}\")\n",
        "print(f\"diffusion model trainable num {sum(p.numel() for p in diffusion_model_lora.parameters() if p.requires_grad)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "params num 862176708\n",
            "trainable num 2655744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kaimao/Desktop/pytorch-stable-diffusion/venv/lib/python3.10/site-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/Users/kaimao/Desktop/pytorch-stable-diffusion/venv/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "LoRA Training Script for Stable Diffusion\n",
        "\n",
        "- Loads images and captions\n",
        "- Prepares data for training\n",
        "- Sets up model with LoRA\n",
        "- Trains only LoRA parameters\n",
        "- Saves LoRA weights compatible with pipeline.generate\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import CLIPTokenizer\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from pipeline import get_time_embedding\n",
        "\n",
        "# --- 1. Dataset ---\n",
        "class StyleDataset(Dataset):\n",
        "    def __init__(self, image_dir, captions_file, image_size=512):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5], [0.5]),\n",
        "        ])\n",
        "        # Read captions\n",
        "        with open(captions_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        self.samples = []\n",
        "        for line in lines:\n",
        "            if ':' in line:\n",
        "                img, cap = line.strip().split(':', 1)\n",
        "                self.samples.append((img.strip(), cap.strip()))\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        img_name, caption = self.samples[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        \n",
        "        return {'image':image, 'caption':caption}\n",
        "\n",
        "# --- 2. Text Encoder Helper (CLIP) ---\n",
        "def encode_text(clip_model, tokenizer, captions, device):\n",
        "    # Tokenize and encode captions using CLIP\n",
        "    # Assumes CLIP model has encode_text method\n",
        "    tokens = tokenizer(captions, padding=True, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        text_embeds = clip_model(tokens.input_ids)\n",
        "    return text_embeds\n",
        "\n",
        "models_with_lora_diffusion = models\n",
        "models_with_lora_diffusion[\"diffusion\"] = diffusion_model_lora\n",
        "batch_size=4\n",
        "epochs=10\n",
        "lr=1e-4\n",
        "device=None\n",
        "\n",
        "if device is None:\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "    elif (hasattr(torch, \"has_mps\") and torch.has_mps) or (hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available()):\n",
        "        device = \"mps\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Tokenizer (use local vocab/merges files)\n",
        "tokenizer = CLIPTokenizer(\"data/vocab.json\", merges_file=\"data/merges.txt\")\n",
        "\n",
        "# Prepare dataset and dataloader\n",
        "dataset = StyleDataset(image_dir, captions_file)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "lora_params = [p for p in diffusion_model_lora.parameters() if p.requires_grad]\n",
        "# Training loop\n",
        "optimizer = torch.optim.Adam(lora_params, lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    models[\"diffusion\"].train()\n",
        "    for batch in dataloader:\n",
        "            images, captions = batch['image'], batch['caption']\n",
        "            \n",
        "            # Move images to device\n",
        "            images = images.to(device)\n",
        "            \n",
        "            # 1. Tokenize captions properly (batch of strings)\n",
        "            tokens = tokenizer(\n",
        "                list(captions),\n",
        "                padding=\"max_length\",\n",
        "                max_length=77,\n",
        "                truncation=True,\n",
        "                return_tensors=\"pt\"\n",
        "            ).input_ids.to(device)\n",
        "            \n",
        "            # 2. Get text embeddings from CLIP (context for cross-attention)\n",
        "            with torch.no_grad():\n",
        "                context = models[\"clip\"](tokens)  # (batch, 77, 768)\n",
        "            \n",
        "            # 3. Encode images to latent space via VAE\n",
        "            with torch.no_grad():\n",
        "                noise = torch.randn_like(mean)\n",
        "                latents = models[\"encoder\"](images, noise)\n",
        "                # VAE outputs 8 channels (mean + log_var), sample from distribution\n",
        "                mean, log_var = torch.chunk(latents, 2, dim=1)\n",
        "                log_var = torch.clamp(log_var, -30, 20)\n",
        "                std = torch.exp(0.5 * log_var)\n",
        "                latents = mean + std * noise\n",
        "                latents = latents * 0.18215  # SD scaling factor\n",
        "            \n",
        "            # 4. Sample random timestep for each image in batch\n",
        "            batch_size = images.shape[0]\n",
        "            timesteps = torch.randint(0, 1000, (batch_size,), device=device)\n",
        "            time_embedding = get_time_embedding(timesteps).to(device)\n",
        "            \n",
        "            # 5. Add noise to latents (forward diffusion)\n",
        "            noise = torch.randn_like(latents)\n",
        "            noisy_latents = add_noise(latents, noise, timesteps)  # You need this function\n",
        "            \n",
        "            # 6. Forward pass - predict noise\n",
        "            optimizer.zero_grad()\n",
        "            predicted_noise = models[\"diffusion\"].unet(noisy_latents, context, time_embedding)\n",
        "            \n",
        "            # 7. Compute loss (MSE between predicted and actual noise)\n",
        "            loss = F.mse_loss(predicted_noise, noise)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{epochs} completed. Loss: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "# Explicitly move all models to CUDA before saving LoRA weights\n",
        "if device == \"cuda\":\n",
        "    for model in models.values():\n",
        "        model.to(\"cuda\")\n",
        "save_models_lora(models, output_path)\n",
        "print(f\"LoRA weights saved to {output_path} (saved from {device})\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Dataset and DataLoader\n",
        "dataset = StyleDataset(image_dir, captions_file)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Load models with LoRA\n",
        "models = preload_models_with_lora(\n",
        "    ckpt_path=ckpt_path,\n",
        "    device=device,\n",
        "    lora_rank=lora_rank,\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    apply_to_diffusion=True,\n",
        "    apply_to_clip=True\n",
        ")\n",
        "diffusion = models['diffusion']\n",
        "clip = models['clip']\n",
        "\n",
        "# Remove duplicate import and initialization of CLIPTokenizer\n",
        "\n",
        "# Only train LoRA parameters\n",
        "for param in diffusion.parameters():\n",
        "    param.requires_grad = False\n",
        "lora_params = get_lora_parameters(diffusion)\n",
        "for param in lora_params:\n",
        "    param.requires_grad = True\n",
        "optimizer = torch.optim.AdamW(lora_params, lr=lr)\n",
        "\n",
        "# --- Training Loop ---\n",
        "for epoch in range(epochs):\n",
        "    diffusion.train()\n",
        "    total_loss = 0\n",
        "    for images, captions in dataloader:\n",
        "        images = images.to(device)\n",
        "        # Encode text\n",
        "        text_embeds = encode_text(clip, tokenizer, list(captions), device)\n",
        "\n",
        "        latents = diffusion.encoder(images)\n",
        "        noise = torch.randn_like(latents)\n",
        "        noisy_latents = latents + noise\n",
        "        pred = diffusion.decoder(noisy_latents)\n",
        "        loss = torch.nn.functional.mse_loss(pred, images)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "    avg_loss = total_loss / len(dataset)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
        "    # Optionally save intermediate LoRA weights\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        save_models_lora(models, f\"{output_path}_epoch{epoch+1}.pt\")\n",
        "# Save final LoRA weights\n",
        "save_models_lora(models, output_path)\n",
        "print(f\"Training complete. LoRA weights saved to {output_path}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iDI2dKfRWTId"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv (3.10.19)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
